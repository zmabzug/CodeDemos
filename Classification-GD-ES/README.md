## Classification-GD-ES
These are a set of pieces of code that I wrote in 2012 to perform logistic regression (classification) on neuronal firing data using gradient descent and early stopping to limit overfitting. The code was written to accommodate two different datasets and use either _leave-one-out_ or K=3-fold cross-validation.

Importantly, in this context, this code was written to test specific hypotheses about neural activity and NOT to make predictions. As a result, instead of a single model that new data can be plugged into, the output of this code is a vector of class predictions, each one derived from a unique model. The number of predictions (and models) is dependent on the type of cross-validation used. You can almost think of this as analogous to bootstrapping: the code performs many iterations (i.e., creates many models), using a subset of the data each time, and uses the remainder of the data to evaluate the model used on that iteration.

### _mlr\_script\_ES.m_
This is the script that runs the whole procedure. The user chooses which dataset to use and which type of cross-validation to perform. The raw data are stored in an _n_ x _t_ binary matrix corresponding to whether or not the neuron fired an action potential in the _t_^th^ 1-ms bin of trial _n_. Since this "rasterized" format leads to very sparse matrices, the convention is to bin data over time (for instance, into 100-ms bins) to count the number of action potentials fired in each sequential bin. Therefore, our predictor matrix _X_ is an _n_ x _b_ matrix of non-negative integers, where _X~nb~_ is the number of action potentials fired during bin _b_ of trial _n_.

The target variable is dependent on the specific dataset used, but it is always an _n_ x 1 binary vector where each element represents whether or not some condition was achieved on trial _n_. If this condition is experimentally-controlled (for instance, whether a visual stimulus is red or blue), then we are typically looking at neural activity in response to that condition. If the condition is a behavioral output (for instance, whether the subject reaches to the left or to the right), then we can either look at neural activity before (i.e., during a potential planning period before the reach is initiated), during, or after the condition is achieved.

### _logitES.m_ & _logitESthirds.m_
_(NOTE: Due to my naivete at the time I wrote this code, the terminology for testing and validation sets is mixed up in these functions: the "testing set" is used to determine when to stop early, and the "validation set" is used to evaluate the model on held-out data. Within this description, my convention will be to talk about testing and validation sets appropriately, rather than how the terminology is used within the functions.)_

These two functions are virtually identical other than the type of testing and cross-validation that they implement. In _logitES.m_, one testing trial is removed, and the rest of the data are evenly and randomly split into a training set to train the model and a validation set to determine when to stop early. The model is then evaluated on the held-out trial. This process is iterated _n_ times, with every trial used as the testing trial exactly once.

In _logitESthirds.m_, one third of the data are removed (testing set), and the rest of the data are evenly and randomly split into a training set to train the model and a validation set to determine when to stop early. The model is then evaluated on the held-out testing set. This process is iterated 20 times with randomized training, validation, and testing sets.